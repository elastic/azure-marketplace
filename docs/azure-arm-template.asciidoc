:marketplace: https://azuremarketplace.microsoft.com/en-au/marketplace/apps/elastic.elasticsearch
:portal: https://portal.azure.com
:github: https://github.com/elastic/azure-marketplace
:elasticdocs: https://www.elastic.co/guide/en/elasticsearch/reference/current
:microsoftdocs: https://docs.microsoft.com
:azurecli: {microsoftdocs}/cli/azure/?view=azure-cli-latest
:azurepowershell: {microsoftdocs}/powershell/azure/overview?view=azurermps-6.4.0
:subscriptions: https://www.elastic.co/subscriptions
:sshkey: {microsoftdocs}/azure/virtual-machines/linux/ssh-from-windows
:resourcegroup: {microsoftdocs}/azure/azure-resource-manager/resource-group-portal
:incrementalmode: {microsoftdocs}/azure/azure-resource-manager/resource-group-template-deploy#incremental-and-complete-deployments
:vms: {microsoftdocs}/azure/virtual-machines/linux/sizes
:azurelocations: https://azure.microsoft.com/en-au/global-infrastructure/locations/
:availabilitysets: {microsoftdocs}/virtual-machines/windows/manage-availability
:availabilityzones: {microsoftdocs}/availability-zones/az-overview
:manageddisks: {microsoftdocs}/azure/virtual-machines/linux/managed-disks-overview
:dns: {microsoftdocs}/azure/virtual-network/virtual-networks-name-resolution-for-vms-and-role-instances#name-resolution-that-uses-your-own-dns-server
:applicationgateway: {microsoftdocs}/azure/application-gateway/application-gateway-introduction
:applicationgatewayfaqs: {microsoftdocs}/azure/application-gateway/application-gateway-faq
:owasp30: https://www.owasp.org/index.php/Category:OWASP_ModSecurity_Core_Rule_Set_Project
:jq: https://stedolan.github.io/jq/
:monit: https://mmonit.com/monit/
:version: 6.3.1

[[azure-arm-template]]
== Azure Resource Manager (ARM) template

The Azure Resource Manager (ARM) template is a declarative solution template that
targets the Azure Resource Manager (ARM) API, to deploy a collection of Azure resources
necessary to run an Elasticsearch cluster on Azure. The ARM API is Microsoft's
infrastructure-as-code offering to provide infrastructure-as-a-service (IaaS) on
the Azure platform, with a consistent API for managing resources.

An ARM template deploys the resources together in a single unit of work, either
as an incremental deployment, which is useful when targeting an existing resource
group, or as a full deployment, which will replace all resources within a resource
group.

[float]
== Getting started

The best way to work with Elastic's ARM template is using one of the official Azure
command line interface (CLI) tools:

{azurecli}[Azure CLI 2.0]:: A Python-based cross platform CLI, typically used
on MacOS and Linux

{azurepowershell}[Azure PowerShell]:: An Azure PowerShell module providing a rich
object oriented API, typically used on Windows

[[logging-in]]
[float]
=== Log in to CLI

Once a CLI is installed, log into an Azure account to use with the CLI

[source,sh]
.Azure CLI 2.0
----
az login
----

[source,powershell]
.Azure PowerShell
----
Login-AzureRmAccount
----

and follow the instructions provided.

[[deploy-elasticsearch-and-kibana]]
[float]
=== Deploy Elasticsearch and Kibana

Now that the CLI is logged in with an account, a deployment can be started. First,
choose a subscription in which to create a resource group and resources

[source,sh]
.Azure CLI 2.0
----
az account set --subscription "<subscription id>"
----

[source,powershell]
.Azure PowerShell
----
Select-AzureRmSubscription -SubscriptionId "<subscription id>"
----

Now that a subscription is selected, create a resource group into which the resources
will be deployed

[source,sh]
.Azure CLI 2.0
----
az group create --name "<name>" --location "<location>"
----

[source,powershell]
.Azure PowerShell
----
New-AzureRmResourceGroup -Name "<name>" -Location "<location>"
----

where

`<name>`:: is a meaningful name to provide the resource group in order to identify
it for future reference
`<location>`:: is a {azurelocations}[valid azure location] for the subscription type

[NOTE]
--
A resource group is a container that holds related resources. As such,
{resourcegroup}[those resources share the same lifecycle, permissions and policies].
A resource group is tied to a specific location, which internally, is where the
Azure infrastructure will persist data related to the resource group, such as
deployments. The resources deployed within a resource group however, do not need
to be deployed to the same location as the resource group; resources within a resource
group can be deployed to any location.
--

Now that a resource group has been created, start a deployment of the ARM
template

[source,sh]
.Azure CLI 2.0
----
template_base_uri=https://raw.githubusercontent.com/elastic/azure-marketplace
template_version=6.3.1

az group deployment create \
  --resource-group "<name>" \
  --template-uri $template_base_uri/$template_version/src/mainTemplate.json \
  --parameters artifactsBaseUrl=$template_base_uri/$template_version/src \
               esVersion=6.3.1 esClusterName=elasticsearch \
               vmDataDiskCount=1 dataNodesAreMasterEligible=Yes \
               adminUsername=russ adminPassword=Password1234 \
               securityBootstrapPassword=bootstrapPassword123 \
               securityAdminPassword=adminPassword123 \
               securityReadPassword=readPassword123 \
               securityKibanaPassword=kibanaPassword123 \
               securityLogstashPassword=logstashPassword123
----

[source,powershell]
.Azure PowerShell
----
$templateBaseUri = "https://raw.githubusercontent.com/elastic/azure-marketplace"
$templateVersion = "6.3.1"

$parameters = @{
  "artifactsBaseUrl" = "$templateBaseUri/$templateVersion/src"
  "esVersion" = "6.3.1"
  "esClusterName" = "elasticsearch"
  "vmDataDiskCount" = 1
  "dataNodesAreMasterEligible" = "Yes"
  "adminUsername" = "russ"
  "adminPassword" = "Password1234"
  "securityBootstrapPassword" = "bootstrapPassword123"
  "securityAdminPassword" = "adminPassword123"
  "securityReadPassword" = "readPassword123"
  "securityKibanaPassword" = "kibanaPassword123"
  "securityLogstashPassword" = "logstashPassword123"
}

$deployment = New-AzureRmResourceGroupDeployment -ResourceGroupName "<name>" `
  -TemplateUri "$templateBaseUri/$templateVersion/src/mainTemplate.json" `
  -TemplateParameterObject $parameters
----

This example will deploy

* an Elasticsearch cluster named elasticsearch
running version 6.3.1
* Kibana 6.3.1.
* The cluster has three master-eligible data nodes, each with a single 1024GB attached managed disk.
* The cluster will have a trial license applied, providing access to Platinum
X-Pack features for 30 days
* X-Pack Security is enabled, and the built-in roles `elastic`, `kibana` and
`logstash_system` are configured, along with an `es_read` user account with readonly
access.

The ARM template accepts _many_ {github}#parameters[parameters], many of which are optional. When a value is not supplied for a parameter, a default value defined within the
ARM template will be used. In the example above, the number of data nodes deployed
uses the default value of 3.

[float]
[[deployment-outputs]]
=== Deployment outputs

When an ARM template deployment completes successfully, the template outputs

`jumpboxssh`:: The public SSH key used when connecting to the jumpbox VM via SSH,
where the `authenticationType` parameter value passed is `sshPublicKey`

`kibana`:: The domain name and port for the public IP address for Kibana,
when `kibana` parameter value passed is `Yes`

`loadbalancer`:: The domain name and port for the public IP address for the
external load balancer, when `loadBalancerType` parameter value passed is `external`

When an output value is not applicable, `"N/A"` is returned.

The values can be retrieved with Azure CLI 2.0 and using, for example, {jq}[`jq`] to
extract the values from JSON

[source,sh]
.Azure CLI 2.0
----
outputs=$(az group deployment show --name mainTemplate \
  --resource-group "<name>" \
  --query properties.outputs)

# jq needs to be installed
jumpboxssh=$(jq -r .jumpboxssh.value <<< $outputs)
kibana=$(jq -r .kibana.value <<< $outputs)
loadbalancer=$(jq -r .loadbalancer.value <<< $outputs)
----

Using Azure PowerShell, the outputs can be retrieved from the `$deployment`
variable assigned as part of the deployment command

[source,powershell]
.Azure PowerShell
----
$jumpboxssh=$deployment.Outputs.jumpboxssh.Value
$kibana=$deployment.Outputs.kibana.Value
$loadbalancer=$deployment.Outputs.loadbalancer.Value
----

[float]
[[delete-resource-group]]
=== Delete resource group

When finished with a deployment and no longer wish to keep the resources or data
around, the easiest way to delete all resources is to delete the resource group
containing the resources, assuming the resource group only contains resources
from the ARM template deployment

[source,sh]
.Azure CLI 2.0
----
az group delete --resource-group "<name>"
----

[source,powershell]
.Azure PowerShell
----
Remove-AzureRmResourceGroup -Name "<name>"
----

That's it for getting started with the ARM template. Read on to learn more about
different parameter and deployment options.

[[elasticsearch-nodes]]
== Elasticseach nodes

The ARM template is able to deploy an Elasticsearch cluster topology with up to 50 data nodes and up to 20 coordinating nodes, along with three dedicated master nodes. The following
sections highlight the parameters that can control {elasticdocs}/modules-node.html[node] deployment options.

Currently, the ARM template deploys _only_ to Ubuntu 16.04-LTS VMs, using images
published to the Azure VM gallery by Canonical, and the {elasticdocs}/deb.html[Debian package distribution of Elasticsearch]. The template uses {monit}[monit] to manage and monitor the Elasticsearch process. monit is configured to run in daemon mode, checking
the state of the Elasticsearch process every 30 seconds; if the process is found to not be running, monit will attempt to start the process.

Elasticsearch can be stopped with monit using

[source,sh]
----
sudo monit stop elasticsearch
----

started with

[source,sh]
----
sudo monit start elasticsearch
----

Refer to {monit}/documentation/monit.html[monit documentation] for further details.

[IMPORTANT]
.Subscription core quota limits
--
The template is able to deploy a cluster up to 73 nodes in size (3 master, 50 data and
20 coordinating nodes), but the largest cluster that you'll be able to deploy will
be governed by the core quota limit defined for the VM SKU targeted and location
within the subscription. You can check what the limit and current use is with
`Subscriptions > Usage + quotas` in the {portal}[Azure portal] or

[source,sh]
.Azure CLI 2.0
----
az vm list-usage --location "<location>"
----

[source,powershell]
.Azure PowerShell
----
Get-AzureRmVMUsage -Location "<location>"
----

Typically, the default limit is 10 per VM SKU family per location. Contact Azure
support to increase the limit for a VM SKU in a specific location.
--

[float]
[[data-nodes]]
=== Data nodes

By default, the template deploys three data nodes. Data nodes hold and perform
data related operations such as search and aggregations. Data node VMs are attached
to the backend pool of load balancers within the template, unless coordinating nodes
are also deployed, in which case coordinating nodes will be attached instead.

`dataNodesAreMasterEligible`::
Either `Yes` or `No` to make data nodes master-eligible. This can be useful for small Elasticsearch clusters. For larger clusters however, it is recommended to have
dedicated master nodes. The default is `No`, and when `Yes` is passed, no
dedicated master nodes will be provisioned.

`vmSizeDataNodes`::
The {vms}[Azure VM SKU] to use for data nodes. Different VM SKUs have different CPU, RAM,
temporary storage space and network bandwidth. Additionally, Different VM SKUs have
different limits to the number of managed disks that can be attached. The default is
`Standard_D1`.

`vmDataNodeCount`::
The number of data nodes. Must be greater than 0. Defaults to 3.

[float]
[[master-nodes]]
=== Master nodes

When `dataNodesAreMasterEligible` parameter is `No`, three dedicated master nodes
will be deployed. Dedicated master nodes are **recommended** for larger clusters.

`vmSizeMasterNodes`::
The {vms}[Azure VM SKU] to use for dedicated master nodes.
Different VM SKUs have different CPU, RAM, temporary storage space and network
bandwidth. The default is `Standard_D1`.

[float]
[[coordinating-nodes]]
=== Coordinating nodes

Coordinating nodes can be deployed with the template; coordinating nodes do not
hold data and are not master-eligible, acting as the coordinators of incoming
requests from clients, sending the request on to data nodes, and gathering the
results to reduce each data node's results into a single global resultset.
Coordinating nodes are a way to scale a cluster deployed with this template
beyond 100 data nodes, the maximum number of VMs that can be added to a
load balancer backend pool; although the template puts a limit of 50 data nodes
within the template, this can be increased by forking the template and increasing
this limit to 100.

If specified, coordinating node VMs are attached to the backend pool of load
balancers within the template, instead of data node VMs.

`vmSizeClientNodes`::
The {vms}[Azure VM SKU] to use for coordinating nodes.
Different VM SKUs have different CPU, RAM, temporary storage space and network
bandwidth. The default is `Standard_D1`.

`vmClientNodeCount`::
The number of coordinating nodes. Defaults to 0.

[float]
=== Ingest and Machine learning nodes

All nodes are configured as Ingest nodes, as well as the Machine
learning nodes if a license that enables Machine learning features has been
applied. Consult the {elasticdocs}/modules-node.html[node] documentation to understand how these can be changed.

[float]
=== Scaling up number of nodes

The template deploys in {incrementalmode}[incremental mode] by default; If a previous solution deployment has been performed into the target resource group, the resources that exist in the resource group __but are not in the template are left unchanged__. All resources that are specified by the solution will be deployed, and for those __resources that already exist and whose settings are unchanged, no change will be made__. For those __resources whose settings are changed however, the resource is provisioned with those new settings__.

If the Elasticsearch deployment script is run on a VM that already has Elasticsearch service running, the elasticsearch configuration file is changed
using parameters from the new deployment. If the node is using the temporary disk
for storage, the script ensures that the data directory and permissions are set appropriately. If a change to the elasticsearch configuration file is detected,
the Elasticsearch service is restarted.

What incremental deployment mode and deployment script behaviour mean in practice
is that it is possible to increase the size of a cluster deployed with the template. There are some caveats to be aware of with this

. A deployment into an existing resource group where the template has already been
deployed *must* use exactly the same parameters, except either `vmDataNodeCount` or
`vmClientNodeCount`, which should be higher (or the same) as the previous deployment to the resource group, to increase the number of data or coordinating
nodes, respectively.
. Template deployment in incremental mode *must* only be used to scale up a
cluster, and not down; the Azure infrastructure has no knowledge of which VMs
can be safely deleted without losing data, since it knows nothing about the shards
and replicas that each node contains.
. Scaling up _should_ only be used when the cluster contains dedicated master
nodes

[float]
=== Availability

Oftentimes you will want to deploy a highly available Elasticsearch cluster that
stays online even in the face of instance or zone failure. Azure has several
concepts to manage Availability.

==== Availability sets

Master, data and coordinating node VMs are grouped in their own
{availabilitysets}[Availability sets], so that at least one machine
is available within a datacentre during a planned or unplanned maintenance event.

[NOTE]
--
The template does not currently use {availabilityzones}[Availability zones] since
they are not yet available in all Azure regions to which the template can be
deployed. It is expected that the template will use Availability zones in the future.
--

==== Update and Fault Domains

Each Availability set has 20 Update domains and two or three Fault domains, depending
on how many Fault domains the selected Azure location supports. When VMs are provisioned, they
are round-robin assigned an Update domain and Fault domain.

Update domains::
Indicate group of virtual machines and underlying physical hardware that can be
rebooted at the same time.

Fault domains::
Indicates group of virtual machines that share a common power source and network switch.
While placing your virtual machines into an availability set does not the cluster
from operating system or Elasticsearch operation failures, it does limit the impact
of potential physical hardware failures, network outages, or power interruptions.

When Elasticsearch is installed onto the VM, the Update and Fault domains in which the
VM resides are specified as node attributes.
{elasticdocs}/allocation-awareness.html[Shard allocation awareness] is configured
taking into account Fault domain and Update domain values.

[[data-disks]]
=== Data disks

{manageddisks}[Managed disks] can be attached to <<data-nodes, Data nodes>> to use as the data directory for the node. The ARM template can attach Standard HDD disks or Premium
managed disks, for those VM SKUs that support them:

`storageAccountType`::
The performance tier of managed disks. `Standard` will use Standard HDD disks,
whilst `Default` will use Premium managed disks for those {vms}[VM SKUs] that support Premium
managed disks, and Standard HDD disks for those that do not. The default is `Default`.

`vmDataDiskSize`::
The size of each attached managed disk. Choose between
+
[horizontal]
`XXLarge`::: 4095 GB
`XLarge`::: 2048 GB
`Large`::: 1024 GB
`Medium`::: 512 GB
`Small`::: 128 GB

+
Default is `Large`.

`vmDataDiskCount`::
The number of managed disks to attach to _each_ data node. The total number of
managed disks will be
+
[source]
----
vmDataNodeCount * vmDataDiskCount
----
+
If the number of disks selected is more than can be attached to the data node VM SKU,
the maximum number of disks that can be attached for the data node VM SKU size
will be used. This is equivalent to
+
[source]
----
Math.min(vmDataDiskCount, data node VM SKU maximum attached disks)
----
+
Must be greater than or equal to 0.
Default is the maximum number of disks supported by the data node VM SKU.

Disks are partitioned with `fdisk` when less than 2TB, and with `parted` when larger,
with an ext4 filesystem and 4096 byte block size.

Data is striped across attached disks per data node in a RAID 0 array, using `mdadm` on Linux. When only one managed disk is attached, no RAID 0 array is configured. When a value of 0 is specified, the data node will use the temp storage of the VM.

include::temp-storage-admonition.asciidoc[]

Striping data across attached disks is recommended to improve Input/Output operations per second (IOPS) performance, since the IOPS and throughput limit per disk can be
combined. The IOPS for Premium disks is higher than for Standard HDD disks, so
Premium disks are recommended where application performance is paramount.

== Networking

=== Virtual network

The template can deploy a new virtual network and attach Elasticsearch and Kibana
to it, or can use an existing virtual network in the same Azure region as the
resource group being deployed to.

Using an existing virtual network requires a subnet to exist to which to attach the deployed resources and a known available private IP address to use as the static address for the internal load balancer, which Kibana will use to communicate with the cluster.
The subnet also needs to have a sufficient number of available IP addresses for all of the resources that will be attached. The following parameters are related to virtual
network configuration

`vNetNewOrExisting`::
Select `new` or `existing` to deploy a new virtual network or use an existing virtual
network, respectively. An existing virtual network in another resource group must exist
in the same Azure location as the target location to be valid. Default is `new`.

`vNetName`::
The name of the virtual network. Defaults to `es-net`.

`vNetClusterSubnetName`::
The name of the subnet to which deployed VMs and load balancers will be attached.
When using an existing virtual network, the subnet must already exist. Defaults
to `es-subnet`.

`vNetLoadBalancerIp`::
The private IP address to use when configuring the internal load balancer.
<<check-private-ip-address-availability, Must be an available IP address>> on
the provided vNetClusterSubnetName. Defaults to `10.0.0.4`.

When deploying a new virtual network, the following parameters also apply

`vNetNewAddressPrefix`::
The address space when creating a new virtual network. Defaults to `10.0.0.0/24`.

`vNetNewClusterSubnetAddressPrefix`::
The address space of the `vNetClusterSubnetName` subnet. Defaults to `10.0.0.0/25`.

When attaching to an existing resource group, the following parameter also applies

`vNetExistingResourceGroup`::
The name of the resource group in which the existing virtual network is deployed.
The resource group must exist in the same Azure location as the target location.

[[check-private-ip-address-availability]]
==== Check private IP address availability

A private IP address can be checked to see if it's available within a virtual network
with

[source,sh]
.Azure CLI 2.0
----
az network vnet check-ip-address --name "<vnet name>" \
  --ip-address "<ip address>"
  --resource-group "<resource group>"
----

[source,powershell]
.Azure PowerShell
----
Test-AzureRmPrivateIPAddressAvailability -VirtualNetworkName "<vnet name>" `
  -IPAddress "<ip address>" `
  -ResourceGroupName "<resource group>"
----

==== Azure DNS resolution

Azure DNS resolution can resolve VMs within a virtual network by hostname, and
is relied upon by the template to form an Elasticsearch cluster, by seeding each
node with the hostnames of each master-eligible node. IP addresses are not used
since they are dynamically allocated to VMs within the template.

[IMPORTANT]
--
The template uses a predictable convention when assigning hostnames to VMs, naming
them `master-`, `data-` and `client-` for master, data and coordinating nodes,
respectively, followed by an incrementing integer starting at 0.

Such a convention is problematic when it comes to deploying more than one cluster
to the same virtual network however; Azure infrastructure does not prevent you
from creating a new VM with the same hostname as an existing VM attached to the
target virtual network, leading to Azure DNS resolving the hostname to the last
attached VM.

For this reason, the template exposes the following parameter

`vmHostNamePrefix`::
Prefix the name of each hostname in the cluster. The prefix can be up to 5
characters in length, must begin with an alphanumeric character and can contain alphanumeric and hyphen characters.
--

If a custom DNS is specified, it's possible to configure your own DNS servers to
resolve hostnames correctly, by {dns}[forwarding DNS queries to Azure to resolve].
This should be configured on the virtual network so that if VMs are shut down or
moved around, they will have the correct configuration when starting up.

=== Load balancing

The template exposes three different load balancing deployment options to suit
different use cases. Each is exposed through

`loadBalancerType`::
Choose between `internal`, `external` or `gateway` to configure an internal load
balancer, external load balancer, or Application Gateway, respectively. Default
is `internal`.

==== Internal load balancer
An OSI layer 4 load balancer configured with a static private IP address on the virtual
network, that can be used to round robin requests across Elasticsearch nodes. The
private IP address is configured with `vNetLoadBalancerIp` parameter.

When coordinating nodes are deployed, they are attached to the internal load balancer
backend pool. When no coordinating nodes are deployed, data nodes are attached to
the backend pool. The load balancer receives incoming requests on port 9200 and
round robins them across the backend pool over port 9200,
with a TCP health probe that checks connectivity every 30 seconds, taking
nodes out of the backend pool when health probes fail.

When Kibana is deployed, Kibana is configured to communicate with Elasticsearch
through the internal load balancer.

==== External load balancer
An OSI layer 4 load balancer configured with a dynamically assigned public IP address
that can be used to send requests to Elasticsearch from the public internet.

When choosing to deploy with an external load balancer, both an internal and
external load balancer are deployed; when Kibana is deployed, it will be
configured to communicate with Elasticsearch through the internal load balancer.
The external load balancer receives incoming requests on port 9200 and
round robins them across the backend pool over port 9201,
with a TCP health probe that checks connectivity every 30 seconds, taking
nodes out of the backend pool when health probes fail. Since both the internal and
external load balancer contain the same VMs in their backend pools, the external load
balancer communicates with the backend pool over port 9201, to work around a limitation
in Azure. On each Elasticsearch node VM, incoming traffic on port 9201 is re-routed
to port 9200 using a persistent `iptables` configuration, and then routed back to
9201 for the outgoing response.

As with the internal load balancer, when coordinating nodes are deployed,
they are attached to the external load balancer backend pool.
When no coordinating nodes are deployed, data nodes are attached to
the backend pool. The load balancer round robins requests across the backend pool
over port 9200, with a TCP health probe that checks connectivity every 30 seconds, taking
nodes out of the backend pool when health probes fail.

==== Application Gateway
An OSI layer 7 load balancer configured with a dynamically assigned public IP address
that can be used to send requests to Elasticsearch from the public internet. {applicationgateway}[Application
Gateway] can be configured with a certificate to configure SSL/TLS between the client
and Application Gateway, performing SSL termination at the gateway. The following parameters are used
to configure Application Gateway

`vNetAppGatewaySubnetName`::
The subnet name for Application Gateway. Application Gateway can only be deployed into
a subnet that contains Application Gateways. When deploying to an existing virtual
network, the subnet must exist beforehand. Defaults to `es-gateway-subnet`.

`vNetNewAppGatewaySubnetAddressPrefix`::
The address space of the Application Gateway subnet. This must be specified when
deploying a new virtual network. The address space must be large enough for the
specified Application Gateway configuration; see {applicationgatewayfaqs}[Application Gateway FAQs]
for more details

`appGatewayTier`::
The tier of Application Gateway. Either `Standard` or `WAF`. The latter is Web
application firewall (WAF), a feature that provides centralized protection from
common exploits and vulnerabilities based on {owasp30}[OWASP core rule sets 3.0].
Defaults to `Standard`.

`appGatewaySku`::
The size of the Application Gateway. Choose `Small`, `Medium` or `Large`.
When choosing `appGatewayTier` of `WAF`, the size must be at least `Medium`. The
main difference between sizes is the amount of throughput that the Gateway can handle.
Defaults to `Medium`.

`appGatewayCount`::
The number of instances of Application Gateway, from 1 to 10. a minimum value
of 2 is recommended for production loads. Defaults to 2.

`appGatewayCertBlob`::
A Base-64 encoded PKCS#12 archive (.p12/.pfx) containing the certificate
and key for Application Gateway. This certificate is used to configure SSL/TLS to
and from Application Gateway. This is required to correctly configure Application
Gateway.

`appGatewayCertPassword`::
The passphrase for the PKCS#12 archive containing the certificate and key for
Application Gateway. Defaults to empty string.

`appGatewayEsHttpCertBlob`::
The Base-64 encoded public certificate (.cer) used to secure the HTTP layer of
Elasticsearch. This is used by Application Gateway to whitelist certificates used
by the backend pool when configuring end-to-end encryption,
and is required when SSL/TLS is configured for the HTTP layer
of Elasticsearch. See the <<tls, Transport Layer Security>> section for more details.

`appGatewayWafStatus`::
When choosing `appGatewayTier` of `WAF`, this parameter controls the firewall
status, either `Enabled` or `Disabled`. Defaults to `Enabled`.

`appGatewayWafMode`::
When choosing `appGatewayTier` of `WAF`, the firewall mode, either `Detection` or
`Prevention`. Defaults to `Detection`.

When choosing to deploy with Application Gateway, both Application Gateway and
an internal load balancer are deployed; the internal load balancer is configured as
the backend pool for Application Gateway.

A custom health probe is configured that reports healthy for the backend pool for
status codes between 200-399, and for status code 401, which may be returned when
X-Pack Security is enabled, since the health probe makes requests without any form
of authentication.

The public IP address of Application Gateway is not returned in the template
outputs, but can be retrieved after successful deployment with

[source,sh]
.Azure CLI 2.0
----
gateway_ip_resource=$(az network public-ip show --name "es-app-gateway-ip" \
  --resource-group "<resource group>")

# jq needs to be installed
gateway_fqdn=$(jq -r .dnsSettings.fqdn <<< $gateway_ip_resource)
gateway_ip="https://${gateway_fqdn}:9200"
----

[source,powershell]
.Azure PowerShell
----
$gatewayIpResource = Get-AzureRmPublicIpAddress -Name "es-app-gateway-ip" `
  -ResourceGroupName "<resource group>"

$gatewayIp = "https://$($gatewayIpResource.DnsSettings.Fqdn):9200"
----

== Security

TODO!

=== Authentication and Authorization

TODO!

=== SAML single sign-on

TODO!

[[tls]]
=== Transport Layer Security

TODO!

==== Elasticsearch

TODO!

===== HTTP layer

TODO!

===== Transport layer

TODO!

==== Kibana

TODO!

== Plugins

TODO!

=== X-Pack

TODO!

=== Azure repository

TODO!

=== Miscellaneous

TODO!

== Troubleshooting

Sometimes, things may go wrong with the deployment for a number of different
reasons including but not limited to

- Incorrect or invalid parameters passed to the template,
that pass initial validation but fail at deployment time
- Transient errors associated with template dependencies
- Transient errors associated with the Azure infrastructure

When such issues arise, you'll need to know where to look to ascertain what the
underlying problem is, in order to determine what action to take to rectify.

=== Accessing nodes
Elasticsearch node VMs are not accessible from outside of the virtual network to which
the cluster is attached. The VMs can be accessed through SSH by either using Kibana
as a jumpbox, or deploying a specific Jumpbox VM. In both cases, a network security
group is configured to allow TCP traffic from the public internet on port 22 to allow
access through SSH.

SSH Authentication will use the authentication mechanism defined by the `authenticationType` parameter, either `password` or `SSH public key`:

[source,sh]
----
ssh <admin username>@<kibana or jumpbox public IP address>
----

Once connected to the Kibana or Jumpbox VM, other VMs on the virtual network can
be accessed using SSH with either the private IP address or VM hostname, if using
Azure DNS to resolve addresses from hostnames

[source,sh]
----
ssh <admin username>@<internal IP address or VM hostname>
----

Many utilities and file paths may require elevated permissions to access, for
example, the elasticsearch configuration file

[source,sh]
----
sudo su
cat /etc/elasticsearch/elasticsearch.yml
----

=== Diagnosing through Azure

TODO!

=== Diagnosing through logs

The log files on each of the Elasticsearch node VMs are a great resource to
understand the current state of the system. The following in particular are most
useful, which you may need administrative privileges on the VM to access:

`/var/log/arm-install.log`::
A log file that the Elasticsearch deployment script writes to. This provides a
chronological timeline for the important events that occur at deployment time,
also giving an indication of how long each takes. Looking at this first provides
an indication as to whether the deployment script completed successfully.

`/var/lib/waagent/custom-script/download/0/stderr`::
A log file that contains log messages written to standard error (stderr) by the Azure infrastructure when the Elasticsearch deployment script runs.

`/var/lib/waagent/custom-script/download/0/stdout`::
A log file that contains log messages written to standard output (stdout) by the Azure infrastructure when the Elasticsearch deployment script runs. There will be
duplication of messages that have been written to `/var/log/arm-install.log`, in addition to other tooling related output such as apt package installations.

`/var/log/monit.log`::
A log file for {monit}[monit], the utility used to manage and monitor the
Elasticsearch service. This log file is useful to check to ensure monit is running correctly.

==== Elasticsearch logs

In addition to template specific and Azure related logs, Elasticsearch log
and configuration files provide invaluable information

Log files in `/var/log/elasticsearch/`::
A collection of different log files written to by the running Elasticsearch
process.

`/etc/elasticsearch/elasticsearch.yml`::
The Elasticsearch configuration log file.

=== Repeatable deployments

For repeatable deployments, it is recommended to target a specific template release
within the {github}[GitHub repository]; Each release is identified by tagging the
commit and the {github}/releases[release notes] indicate the changes in the release.

Targeting a specific release ensures that the template parameters remain the same,
in addition to which resources are deployed and how they are configured. Furthermore,
a release undergoes considerable testing before being considered ready for public
release.

As an example, to target {version} release of the template

[source,sh]
[subs="verbatim,attributes"]
.Azure CLI 2.0
----
template_base_uri=https://raw.githubusercontent.com/elastic/azure-marketplace
template_version={version}

az group deployment create \
  --resource-group "<name>" \
  --template-uri $template_base_uri/$template_version/src/mainTemplate.json \
  --parameters artifactsBaseUrl=$template_base_uri/$template_version/src \
               esVersion={version} esClusterName=elasticsearch \
               vmDataDiskCount=1 dataNodesAreMasterEligible=Yes \
               adminUsername=russ adminPassword=Password1234 \
               securityBootstrapPassword=bootstrapPassword123 \
               securityAdminPassword=adminPassword123 \
               securityReadPassword=readPassword123 \
               securityKibanaPassword=kibanaPassword123 \
               securityLogstashPassword=logstashPassword123
----

[source,powershell]
[subs="verbatim,attributes"]
.Azure PowerShell
----
$templateBaseUri = "https://raw.githubusercontent.com/elastic/azure-marketplace"
$templateVersion = "{version}"

$parameters = @{
  "artifactsBaseUrl" = "$templateBaseUri/$templateVersion/src"
  "esVersion" = "{version}"
  "esClusterName" = "elasticsearch"
  "vmDataDiskCount" = 1
  "dataNodesAreMasterEligible" = "Yes"
  "adminUsername" = "russ"
  "adminPassword" = "Password1234"
  "securityBootstrapPassword" = "bootstrapPassword123"
  "securityAdminPassword" = "adminPassword123"
  "securityReadPassword" = "readPassword123"
  "securityKibanaPassword" = "kibanaPassword123"
  "securityLogstashPassword" = "logstashPassword123"
}

$deployment = New-AzureRmResourceGroupDeployment -ResourceGroupName "<name>" `
  -TemplateUri "$templateBaseUri/$templateVersion/src/mainTemplate.json" `
  -TemplateParameterObject $parameters
----
