:marketplace: https://azuremarketplace.microsoft.com/en-au/marketplace/apps/elastic.elasticsearch
:portal: https://portal.azure.com
:github: https://github.com/elastic/azure-marketplace
:current: 7.7
:version: 7.7.0
:register: https://register.elastic.co
:elasticguide: https://www.elastic.co/guide/en/elasticsearch
:elasticdocs: {elasticguide}/reference/{current}
:elasticstack: https://www.elastic.co/products/stack
:stackdocs: https://www.elastic.co/guide/en/elastic-stack-overview/{current}
:xpackenabled: {elasticdocs}/security-settings.html#general-security-settings
:bootstrappassword: : {stackdocs}/built-in-users.html#bootstrap-elastic-passwords
:licenseexpiration: {stackdocs}/license-expiration.html
:microsoftdocs: https://docs.microsoft.com
:azuredocs: https://azure.microsoft.com
:azurecli: {microsoftdocs}/cli/azure/?view=azure-cli-latest
:azurepowershell: {microsoftdocs}/powershell/azure/overview
:subscriptions: https://www.elastic.co/subscriptions
:sshkey: {microsoftdocs}/azure/virtual-machines/linux/ssh-from-windows
:resourcegroup: {microsoftdocs}/azure/azure-resource-manager/resource-group-portal
:incrementalmode: {microsoftdocs}/azure/azure-resource-manager/resource-group-template-deploy#incremental-and-complete-deployments
:vms: {microsoftdocs}/azure/virtual-machines/linux/sizes
:azurelocations: {azuredocs}/en-au/global-infrastructure/locations/
:availabilitysets: {microsoftdocs}/azure/virtual-machines/linux/manage-availability
:availabilityzones: {microsoftdocs}/azure/availability-zones/az-overview
:manageddisks: {microsoftdocs}/azure/virtual-machines/linux/managed-disks-overview
:dns: {microsoftdocs}/azure/virtual-network/virtual-networks-name-resolution-for-vms-and-role-instances#name-resolution-that-uses-your-own-dns-server
:applicationgateway: {microsoftdocs}/azure/application-gateway/application-gateway-introduction
:applicationgatewayfaqs: {microsoftdocs}/azure/application-gateway/application-gateway-faq
:applicationmanifest: {microsoftdocs}/azure/active-directory/develop/active-directory-application-manifest
:owasp30: https://www.owasp.org/index.php/Category:OWASP_ModSecurity_Core_Rule_Set_Project
:jq: https://stedolan.github.io/jq/
:systemd: https://www.freedesktop.org/wiki/Software/systemd/
:yamllint: http://www.yamllint.com/
:openssl: https://www.openssl.org/docs/man1.0.2/apps/openssl.html
:base64: https://linux.die.net/man/1/base64
:acceleratednetworking: {azuredocs}/en-us/blog/maximize-your-vm-s-performance-with-accelerated-networking-now-generally-available-for-both-windows-and-linux/
:loadbalancers: {microsoftdocs}/azure/load-balancer/load-balancer-standard-overview

[[azure-arm-template]]
== Azure Resource Manager (ARM) template

The Azure Resource Manager (ARM) template is a declarative solution template that
targets the Azure Resource Manager (ARM) API, to deploy a collection of Azure resources
necessary to run an Elasticsearch cluster on Azure. The ARM API is Microsoft's
infrastructure-as-code offering to provide infrastructure-as-a-service (IaaS) on
the Azure platform, with a consistent API for managing resources.

An ARM template deploys the resources together in a single unit of work, either
as an incremental deployment, which is useful when targeting an existing resource
group, or as a full deployment, which will replace all resources within a resource
group.

[[azure-arm-template-getting-started]]
=== Getting started with the ARM template

The best way to work with Elastic's ARM template is using one of the official Azure
command line interface (CLI) tools:

{azurecli}[Azure CLI 2.0]:: A Python-based cross platform CLI, typically used
on MacOS and Linux

{azurepowershell}[Azure PowerShell]:: An Azure PowerShell module providing a rich
object oriented API, typically used on Windows

[[logging-in-to-cli]]
==== Log in to CLI

Once a CLI is installed, log into an Azure account to use with the CLI

[source,sh]
.Azure CLI 2.0
----
az login
----

[source,powershell]
.Azure PowerShell
----
Login-AzureRmAccount
----

and follow the instructions provided.

[[deploy-elasticsearch-and-kibana]]
[float]
=== Deploy Elasticsearch and Kibana

Now that the CLI is logged in with an account, a deployment can be started. First,
choose a subscription in which to create a resource group and resources

[source,sh]
.Azure CLI 2.0
----
az account set --subscription "<subscription id>"
----

[source,powershell]
.Azure PowerShell
----
Select-AzureRmSubscription -SubscriptionId "<subscription id>"
----

Now that a subscription is selected, create a resource group into which the resources
will be deployed

[source,sh]
.Azure CLI 2.0
----
az group create --name "<name>" --location "<location>"
----

[source,powershell]
.Azure PowerShell
----
New-AzureRmResourceGroup -Name "<name>" -Location "<location>"
----

where

`<name>`:: is a meaningful name to provide the resource group in order to identify
it for future reference
`<location>`:: is a valid {azurelocations}[Azure location] for the subscription

[NOTE]
--
A resource group is a container that holds related resources. As such,
{resourcegroup}[those resources share the same lifecycle, permissions and policies].
A resource group is tied to a specific location, which internally, is where the
Azure infrastructure will persist data related to the resource group, such as
deployments. The resources deployed within a resource group however, do not need
to be deployed to the same location as the resource group; resources within a resource
group can be deployed to any location.
--

Now that a resource group has been created, start a deployment of the ARM
template

[source,sh]
[subs="attributes"]
.Azure CLI 2.0
----
template_base_uri=https://raw.githubusercontent.com/elastic/azure-marketplace
template_version={version}

az group deployment create \
  --resource-group "<name>" \
  --template-uri $template_base_uri/$template_version/src/mainTemplate.json \
  --parameters _artifactsLocation=$template_base_uri/$template_version/src/ \
               esVersion={version} esClusterName=elasticsearch \
               vmDataDiskCount=1 dataNodesAreMasterEligible=Yes \
               adminUsername=russ adminPassword=Password1234 \
               securityBootstrapPassword=bootstrapPassword123 \
               securityAdminPassword=adminPassword123 \              
               securityKibanaPassword=kibanaPassword123 \
               securityLogstashPassword=logstashPassword123 \
               securityBeatsPassword=beatsPassword123 \
               securityApmPassword=apmPassword123 \
               securityRemoteMonitoringPassword=remoteMonitoringPassword123
----

[source,powershell]
[subs="attributes"]
.Azure PowerShell
----
$templateBaseUri = "https://raw.githubusercontent.com/elastic/azure-marketplace"
$templateVersion = "{version}"

$parameters = @{
  "_artifactsLocation" = "$templateBaseUri/$templateVersion/src/"
  "esVersion" = "{version}"
  "esClusterName" = "elasticsearch"
  "vmDataDiskCount" = 1
  "dataNodesAreMasterEligible" = "Yes"
  "adminUsername" = "russ"
  "adminPassword" = "Password1234"
  "securityBootstrapPassword" = "bootstrapPassword123"
  "securityAdminPassword" = "adminPassword123"
  "securityKibanaPassword" = "kibanaPassword123"
  "securityLogstashPassword" = "logstashPassword123"
  "securityBeatsPassword" = "beatsPassword123"
  "securityApmPassword" = "apmPassword123"
  "securityRemoteMonitoringPassword" = "remoteMonitoringPassword123"
}

$deployment = New-AzureRmResourceGroupDeployment -ResourceGroupName "<name>" `
  -TemplateUri "$templateBaseUri/$templateVersion/src/mainTemplate.json" `
  -TemplateParameterObject $parameters
----

This example will deploy

* an Elasticsearch cluster named elasticsearch
running version {version}
* Kibana {version}.
* The cluster has three master-eligible data nodes, each with a single 1024GB attached managed disk.
* The cluster will have a trial license applied, providing access to Elastic Stack Platinum features for 30 days
* Security feature is enabled, and the {xpackdocs}/built-in-roles.html[built-in users] `elastic`, `kibana`,
`logstash_system`, `apm_system` and `remote_monitoring_user` are configured.

The ARM template accepts _many_ {github}#parameters[parameters], many of which are optional. When a value is not supplied for a parameter, a default value defined within the
ARM template will be used. In the example above, the number of data nodes deployed
uses the default value of 3.

[[deployment-outputs]]
[float]
=== Deployment outputs

When an ARM template deployment completes successfully, the template outputs

`jumpboxssh`:: The public SSH key used when connecting to the jumpbox VM via SSH,
where the `authenticationType` parameter value passed is `sshPublicKey`

`kibana`:: The domain name and port for the public IP address for Kibana,
when `kibana` parameter value passed is `Yes`

`loadbalancer`:: The domain name and port for the public IP address for the
external load balancer, when `loadBalancerType` parameter value passed is `external`

When an output value is not applicable, `"N/A"` is returned.

The values can be retrieved with Azure CLI 2.0 and using, for example, {jq}[`jq`] to
extract the values from JSON

[source,sh]
.Azure CLI 2.0
----
outputs=$(az group deployment show --name mainTemplate \
  --resource-group "<name>" \
  --query properties.outputs)

# jq needs to be installed
jumpboxssh=$(jq -r .jumpboxssh.value <<< $outputs)
kibana=$(jq -r .kibana.value <<< $outputs)
loadbalancer=$(jq -r .loadbalancer.value <<< $outputs)
----

Using Azure PowerShell, the outputs can be retrieved from the `$deployment`
variable assigned as part of the deployment command

[source,powershell]
.Azure PowerShell
----
$jumpboxssh = $deployment.Outputs.jumpboxssh.Value
$kibana = $deployment.Outputs.kibana.Value
$loadbalancer = $deployment.Outputs.loadbalancer.Value
----

[[delete-resource-group]]
[float]
=== Delete resource group

When finished with a deployment and no longer wish to keep the resources or data
around, the easiest way to delete all resources is to delete the resource group
containing the resources, **assuming the resource group _only_ contains resources
from the ARM template deployment**

[source,sh]
.Azure CLI 2.0
----
az group delete --resource-group "<name>"
----

[source,powershell]
.Azure PowerShell
----
Remove-AzureRmResourceGroup -Name "<name>"
----

That's it for getting started with the ARM template. Read on to learn more about
different parameter and deployment options.

[[azure-arm-template-configuration]]
=== Template configuration

The ARM template has some general parameters that control the operation of the
template:

`_artifactsLocation`::
The base public URI which informs the main template from where the other contents
of the ARM template will be retrieved, such as linked templates and deployment scripts.
Default is `https://raw.githubusercontent.com/elastic/azure-marketplace/{branch}/src/`
where `{branch}` is the git branch or tag to target, for
<<azure-arm-template-repeatable-deployments, repeatable deployments>>. The value must end
in a trailing `/`.

`_artifactsLocationSasToken`::
The sasToken required to access `_artifactsLocation`. The default value should be an empty 
string `""`` for scenarios where the `_artifactsLocation` is not secured, such as the raw GitHub 
URI for the Azure Marketplace public repo.

`location`::
The {azurelocations}[Azure location] in which to deploy the resources. Defaults to the same location
as the target resource group of the deployment. All deployed resources are deployed
to this location.

[[azure-arm-template-elasticsearch]]
=== Elasticsearch

The ARM template is able to deploy an Elasticsearch cluster topology with up to 50 data nodes and up to 20 coordinating nodes, along with three dedicated master nodes. The following
sections highlight the parameters that can control {elasticdocs}/modules-node.html[node] deployment options.

[IMPORTANT]
.Subscription core quota limits
--
The template is able to deploy a cluster up to 73 nodes in size (3 master, 50 data and
20 coordinating nodes), but the largest cluster that you'll be able to deploy will
be governed by the core quota limit defined for the VM SKU targeted and location
within the subscription. You can check what the limit and current use is with
`Subscriptions > Usage + quotas` in the {portal}[Azure portal] or

[source,sh]
.Azure CLI 2.0
----
az vm list-usage --location "<location>"
----

[source,powershell]
.Azure PowerShell
----
Get-AzureRmVMUsage -Location "<location>"
----

Typically, the default limit is 10 per VM SKU family per location. Contact Azure
support to increase the limit for a VM SKU in a specific location.
--

Currently, the ARM template deploys _only_ to Ubuntu 16.04-LTS VMs, using images
published to the Azure VM gallery by Canonical, and the {elasticdocs}/deb.html[Debian package distribution of Elasticsearch]. The template uses {systemd}[systemd] to run the Elasticsearch process, with Elasticsearch configured
to start automatically when the system boots up.

Elasticsearch can be stopped with systemd <<azure-arm-template-troubleshooting-accessing-nodes, on an Elasticsearch VM node>> using

[source,sh]
----
sudo systemctl stop elasticsearch.service
----

and started with

[source,sh]
----
sudo systemctl start elasticsearch.service
----

[[azure-arm-template-admin-username]]
==== Virtual machine admin username

All VMs deployed by the template are secured with a username and either a password
or SSH key

`adminUsername`::
Admin username used when provisioning VMs. Must be a valid Linux username
i.e. https://azure.microsoft.com/en-us/documentation/articles/virtual-machines-linux-usernames/#ubuntu[avoid any usernames that are invalid for Ubuntu]

`authenticationType`::
The authentication mechanism to use to access VMs. Can be either `password` or
`sshPublicKey`.

`adminPassword`::
When `authenticationType` is `password`, the password to use for the Admin username
to access VMs.

`sshPublicKey`::
When `authenticationType` is `sshPublicKey`, the public SSH key to use for the
Admin username to access VMs.

[[azure-arm-template-cluster-settings]]
==== Cluster settings

The following are general settings that control cluster configuration

`esVersion`::
The version of Elasticsearch (and thus, Kibana) to deploy. Each template version
is capable of deploying many different versions, with the template version number
giving an indication of what the default stack version will be. For example,
{github}/blob/{version}/src/mainTemplate.json#L22-L49[template
version {version} will deploy Elasticsearch {version}] by default. Consult
`esVersion.allowedValues` array in mainTemplate.json file of a specific template version to
ascertain which versions it can deploy.

`esClusterName`::
The name of the Elasticsearch cluster. It's recommended to choose an appropriate name
that describes the purpose of the cluster. This value is **required**

`esHeapSize`::
The amount of memory, in megabytes, to allocate on each
{elasticdocs}/heap-size.html[Elasticsearch node for the JVM heap].
Default will allocate 50% of the available memory will be allocated to Elasticsearch heap,
up to a maximum of 31,744MB (approximately 32GB).
+
This is an expert level feature; setting a heap size too low or larger than available
memory on the chosen Elasticsearch VM SKU will fail the deployment.

`esAdditionalYaml`::
Additional configuration for Elasticsearch yml configuration file.
Each line must be separated by a `\n` newline character. For example,
+
[source,sh]
----
"action.auto_create_index: +.*\nindices.queries.cache.size: 5%"
----
+
It is recommended that you run your additional yaml through a {yamllint}[linter]
before starting a deployment, as incorrectly formatted yaml will fail the deployment.

[[azure-arm-template-data-nodes]]
==== Data nodes

By default, the template deploys three data nodes. Data nodes hold and perform
data related operations such as search and aggregations. Data node VMs are attached
to the backend pool of load balancers within the template, unless coordinating nodes
are also deployed, in which case coordinating nodes will be attached instead.

`dataNodesAreMasterEligible`::
Either `Yes` or `No` to make data nodes master-eligible. This can be useful for small Elasticsearch clusters. For larger clusters however, it is recommended to have
dedicated master nodes. The default is `No`, and when `Yes` is passed, no
dedicated master nodes will be provisioned.

`vmSizeDataNodes`::
The {vms}[Azure VM SKU] to use for data nodes. Different VM SKUs have different CPU, RAM,
temporary storage space and network bandwidth. Additionally, Different VM SKUs have
different limits to the number of managed disks that can be attached. The default is
`Standard_DS1_v2`.

`vmDataNodeCount`::
The number of data nodes. Must be greater than 0. Defaults to 3.

`vmDataNodeAcceleratedNetworking`::
Whether to enable {acceleratednetworking}[accelerated networking] for data nodes,
which enables single root I/O virtualization (SR-IOV) to a VM, greatly improving its
networking performance. Valid values are `Default`, `Yes`, `No`. The default is `Default`, which
enables accelerated networking for the VM SKUs known to support it.

[[azure-arm-template-master-nodes]]
==== Master nodes

When `dataNodesAreMasterEligible` parameter is `No`, three dedicated master nodes
will be deployed. Dedicated master nodes are **recommended** for larger clusters.

`vmSizeMasterNodes`::
The {vms}[Azure VM SKU] to use for dedicated master nodes.
Different VM SKUs have different CPU, RAM, temporary storage space and network
bandwidth. The default is `Standard_DS1_v2`.

`vmMasterNodeAcceleratedNetworking`::
Whether to enable {acceleratednetworking}[accelerated networking] for dedicated master nodes,
which enables single root I/O virtualization (SR-IOV) to a VM, greatly improving its
networking performance. Valid values are `Default`, `Yes`, `No`. The default is `Default`, which
enables accelerated networking for the VM SKUs known to support it.

[[azure-arm-template-coordinating-nodes]]
==== Coordinating nodes

Coordinating nodes can optionally be deployed with the template; coordinating nodes do not
hold data and are not master-eligible, but act as the coordinators of incoming
requests from clients, sending those request on to data nodes, and gathering the
results to reduce each data node's results into a single global resultset.
Coordinating nodes are a way to scale a cluster deployed with this template
beyond 100 data nodes, the maximum number of VMs that can be added to a
load balancer backend pool; although the template puts a limit of 50 data nodes
within the template, this can be increased by forking the template and increasing
this limit to 100.

If specified, coordinating node VMs are attached to the backend pool of load
balancers within the template, instead of data node VMs.

`vmSizeClientNodes`::
The {vms}[Azure VM SKU] to use for coordinating nodes.
Different VM SKUs have different CPU, RAM, temporary storage space and network
bandwidth. The default is `Standard_DS1_v2`.

`vmClientNodeCount`::
The number of coordinating nodes. Defaults to 0.

`vmClientNodeAcceleratedNetworking`::
Whether to enable {acceleratednetworking}[accelerated networking] for coordinating nodes,
which enables single root I/O virtualization (SR-IOV) to a VM, greatly improving its
networking performance. Valid values are `Default`, `Yes`, `No`. The default is `Default`, which
enables accelerated networking for the VM SKUs known to support it.

[[azure-arm-template-ingest-ml-nodes]]
==== Ingest and Machine learning nodes

All deployed nodes are configured as Ingest nodes, as well as Machine
learning nodes, if a license that enables Machine learning features has been
applied. Consult the {elasticdocs}/modules-node.html[node] documentation to
understand how node roles can be changed.

[[azure-arm-template-scaling-nodes]]
[float]
=== Scaling up number of nodes

The template deploys in {incrementalmode}[incremental mode] by default; If a previous
solution deployment has been performed into the target resource group, the resources
that exist in the resource group __but are not in the template are left unchanged__.
All resources that are specified by the solution will be deployed, and for those
__resources that already exist and whose settings are unchanged, no change will be made__.
For those __resources whose settings are changed however, the resource is provisioned with those new settings__.

If the Elasticsearch deployment script is run on a VM that already has Elasticsearch
process running, the elasticsearch.yml configuration file is changed
using parameters from the new deployment. If the node is using the temporary disk
for storage, the script ensures that the data directory and permissions are set appropriately. If a change to the elasticsearch configuration file is detected, the Elasticsearch process is restarted.

What incremental deployment mode and deployment script behaviour mean in practice
is that it is possible to increase the size of a cluster deployed with the template. There are some caveats to be aware of

. A deployment into an existing resource group where the template has already been
deployed *must* use exactly the same parameters, except either `vmDataNodeCount` or
`vmClientNodeCount`, which should be higher (or the same) as the previous deployment to the resource group, to increase the number of data or coordinating
nodes, respectively.
. Template deployment in incremental mode *must* only be used to scale up a
cluster, and not down; the Azure infrastructure has no knowledge of which VMs
can be safely deleted without losing data, since it knows nothing about the shards
and replicas that each node contains.
. Scaling up _should_ only be used when the cluster contains dedicated master
nodes

[[azure-arm-template-data-disks]]
=== Data disks

{manageddisks}[Managed disks] can be attached to <<azure-arm-template-data-nodes, Data nodes>> to use as the data directory for the node. The ARM template can attach Standard HDD disks or Premium
managed disks, for those VM SKUs that support them:

`storageAccountType`::
The performance tier of managed disks. `Standard` will use Standard HDD disks,
whilst `Default` will use Premium managed disks for those {vms}[VM SKUs] that support Premium
managed disks, and Standard HDD disks for those that do not. The default is `Default`.

`vmDataDiskSize`::
The size of each attached managed disk. Choose between
+
[horizontal]
`32TiB`::: 32 Tebibytes
`16TiB`::: 16 Tebibytes
`8TiB`::: 8 Tebibytes
`4TiB`::: 4 Tebibytes
`2TiB`::: 2 Tebibytes
`1TiB`::: 1 Tebibyte
`512GiB`::: 512 Gibibytes
`256GiB`::: 256 Gibibytes
`128GiB`::: 126 Gibibytes
`64GiB`::: 64 Gibibytes
`32GiB`::: 32 Gibibytes

+
Default is `1TiB`.

`vmDataDiskCount`::
The number of managed disks to attach to _each_ data node. The total number of
managed disks will be
+
[source,sh]
----
vmDataNodeCount * vmDataDiskCount
----
+
If the number of disks selected is more than can be attached to the data node VM SKU,
the maximum number of disks that can be attached for the data node VM SKU size
will be used. This is equivalent to
+
[source,sh]
----
Math.min(vmDataDiskCount, data node VM SKU maximum attached disks)
----
+
Must be greater than or equal to 0.
Default is the maximum number of disks supported by the data node VM SKU.

Disks are partitioned with `fdisk` when less than 2TB, and with `parted` when larger,
with an ext4 filesystem and 4096 byte block size.

Data is striped across attached disks per data node in a RAID 0 array, using `mdadm` on Linux. When only one managed disk is attached, no RAID 0 array is configured. When a value of 0 is specified, the data node will use the temp storage of the VM.

include::temp-storage-admonition.asciidoc[]

Striping data across attached disks is recommended to improve Input/Output operations per second (IOPS) performance, since the IOPS and throughput limit per disk can be
combined. The IOPS for Premium disks is higher than for Standard HDD disks, so
Premium disks are recommended where application performance is paramount.

[[azure-arm-template-availability]]
=== Availability

Oftentimes you will want to deploy a highly available Elasticsearch cluster that
stays online even in the face of instance or zone failure. Azure has several
concepts to manage Availability.

[[availability-sets]]
==== Availability sets

Master, data and coordinating node VMs are grouped in their own
{availabilitysets}[Availability sets], so that at least one machine
is available within a datacentre during a planned or unplanned maintenance event.

[NOTE]
--
The template does not currently use {availabilityzones}[Availability zones] since
they are not yet available in all Azure regions to which the template can be
deployed. It is expected that the template will use Availability zones in the future.
--

[[update-and-fault-domains]]
==== Update and Fault Domains

Each Availability set has 20 Update domains and two or three Fault domains, depending
on how many Fault domains the selected Azure location supports. When VMs are provisioned, they
are round-robin assigned an Update domain and Fault domain.

Update domains::
Indicates a group of virtual machines and underlying physical hardware that can be
rebooted at the same time.

Fault domains::
Indicates a group of virtual machines that share a common power source and network switch.
While placing your virtual machines into an availability set does not mitigate
operating system or Elasticsearch operation failures, it does limit the impact
of potential physical hardware failures, network outages, or power interruptions.

When Elasticsearch is installed onto the VM, the Update and Fault domains in which the
VM resides are specified as node attributes in the elasticsearch.yml configuration file.
{elasticdocs}/allocation-awareness.html[Shard allocation awareness] is configured
taking into account these Fault domain and Update domain attribute values.

[[azure-arm-template-networking]]
=== Networking

[[virtual-network]]
==== Virtual network

The template can deploy a new virtual network and attach Elasticsearch and Kibana
to it, or can use an existing virtual network in the same Azure region as the
resource group being deployed to.

Using an existing virtual network requires a subnet to exist to which to attach the deployed resources and a known available private IP address to use as the static address for the internal load balancer, which Kibana will use to communicate with the cluster.
The subnet also needs to have a sufficient number of available IP addresses for all of the resources that will be attached. The following parameters are related to virtual
network configuration

`vNetNewOrExisting`::
Select `new` or `existing` to deploy a new virtual network or use an existing virtual
network, respectively. An existing virtual network in another resource group must exist
in the same Azure location as the target location to be valid. Default is `new`.

`vNetName`::
The name of the virtual network. Defaults to `es-net`.

`vNetClusterSubnetName`::
The name of the subnet to which deployed VMs and load balancers will be attached.
When using an existing virtual network, the subnet must already exist. Defaults
to `es-subnet`.

`vNetLoadBalancerIp`::
The private IP address to use when configuring the internal load balancer.
<<check-private-ip-address-availability, Must be an available IP address>> on
the provided vNetClusterSubnetName. Defaults to `10.0.0.4`.

When deploying a new virtual network, the following parameters also apply

`vNetNewAddressPrefix`::
The address space when creating a new virtual network. Defaults to `10.0.0.0/24`.

`vNetNewClusterSubnetAddressPrefix`::
The address space of the `vNetClusterSubnetName` subnet. Defaults to `10.0.0.0/25`.

When attaching to an existing resource group, the following parameter also applies

`vNetExistingResourceGroup`::
The name of the resource group in which the existing virtual network is deployed.
The resource group must exist in the same Azure location as the target location.

[[check-private-ip-address-availability]]
==== Check private IP address availability

A private IP address can be checked to see if it's available within a virtual network
with

[source,sh]
.Azure CLI 2.0
----
az network vnet check-ip-address --name "<vnet name>" \
  --ip-address "<ip address>" \
  --resource-group "<resource group>"
----

[source,powershell]
.Azure PowerShell
----
Test-AzureRmPrivateIPAddressAvailability -VirtualNetworkName "<vnet name>" `
  -IPAddress "<ip address>" `
  -ResourceGroupName "<resource group>"
----

[[dns-resolution]]
==== Azure DNS resolution

Azure DNS resolution can resolve VMs within a virtual network by hostname, and
is relied upon by the template to form an Elasticsearch cluster, by seeding each
node with the hostnames of each master-eligible node. IP addresses are not used
since they are dynamically allocated to VMs within the template.

[IMPORTANT]
--
The template uses a predictable convention when assigning hostnames to VMs, naming
them `master-`, `data-` and `client-` for master, data and coordinating nodes,
respectively, followed by an incrementing integer starting at 0.

Such a convention is problematic when it comes to deploying more than one cluster
to the same virtual network however; Azure infrastructure does not prevent you
from creating a new VM with the same hostname as an existing VM attached to the
target virtual network, leading to Azure DNS resolving the hostname to the last
attached VM.

For this reason, the template exposes the following parameter

`vmHostNamePrefix`::
Prefix the name of each hostname in the cluster. The prefix can be up to 5
characters in length, must begin with an alphanumeric character and can contain alphanumeric and hyphen characters.
--

If a custom DNS is specified, it's possible to configure your own DNS servers to
resolve hostnames correctly, by {dns}[forwarding DNS queries to Azure to resolve].
This should be configured on the virtual network so that if VMs are shut down or
moved around, they will have the correct configuration when starting up.

[[azure-arm-template-load-balancing]]
=== Load balancing

The template exposes three different load balancing deployment options to suit
different use cases. Each is exposed through

`loadBalancerType`::
Choose between `internal`, `external` or `gateway` to configure an internal load
balancer, external load balancer, or Application Gateway, respectively. Default
is `internal`.

[[internal-load-balancer]]
==== Internal load balancer
An OSI layer 4 load balancer configured with a static private IP address on the virtual
network, that can be used to round robin requests across Elasticsearch nodes. The
private IP address is configured with `vNetLoadBalancerIp` parameter.

The following settings apply to the internal load balancer

`loadBalancerInternalSku`::
Choose between `Basic` and `Standard` load balancer SKUs for the internal load balancer. An
internal load balancer is **always** deployed, to balance internal traffic to the cluster. When 
the `Standard` load balancer SKU is selected and `loadBalancerType` is `internal`, a Network 
Security Group will also be deployed, and each VM in the backend pool will be assigned 
a `Standard` public IP address, to allow outbound internet traffic from the VMs in the backend 
pool, which is required to install the Elastic Stack and dependencies.
{loadbalancers}[Check the Azure documentation on Standard Load Balancers] to determine which
options is best suited for your needs. Default is `Basic`.

When coordinating nodes are deployed, they are attached to the internal load balancer
backend pool. When no coordinating nodes are deployed, the data nodes are attached to
the backend pool. The load balancer receives incoming requests on port 9200 and
round robins them across the backend pool over port 9200,
with a TCP health probe that checks connectivity every 30 seconds, taking
nodes out of the backend pool when health probes fail. An idle timeout of 5 minutes
is also configured.

When Kibana is deployed, Kibana is configured to communicate with Elasticsearch
through the internal load balancer.

[[external-load-balancer]]
==== External load balancer
An OSI layer 4 load balancer configured with a public IP address
that can be used to send requests to Elasticsearch from the public internet.

The following settings are applicable to the external load balancer

`loadBalancerExternalSku`::
Choose between `Basic` and `Standard` load balancer SKUs for the external load balancer. Only
relevant when `loadBalancerType` is `external`. When the `Standard` load balancer SKU is selected,
the public IP address SKU attached to the external load balancer will also be `Standard`, and a
Network Security Group will also be deployed, to allow inbound internet traffic to the VMs in the backend pool.
{loadbalancers}[Check the Azure documentation on Standard Load Balancers] to determine which
options is best suited for your needs. Default is `Basic`.

When choosing to deploy with an external load balancer, both an internal and
external load balancer are deployed; when Kibana is deployed, it will be
configured to communicate with Elasticsearch through the internal load balancer.
The external load balancer receives incoming requests on port 9200 and
round robins them across the backend pool over port 9201,
with a TCP health probe that checks connectivity every 30 seconds, taking
nodes out of the backend pool when health probes fail. Since both the internal and
external load balancer contain the same VMs in their backend pools, the external load
balancer communicates with the backend pool over port 9201, to work around a limitation
in Azure. On each Elasticsearch node VM, incoming traffic on port 9201 is re-routed
to port 9200 using a persistent `iptables` configuration, and then routed back to
9201 for the outgoing response.

As with the internal load balancer, when coordinating nodes are deployed,
they are attached to the external load balancer backend pool.
When no coordinating nodes are deployed, data nodes are attached to
the backend pool. The load balancer round robins requests across the backend pool
over port 9200, with a TCP health probe that checks connectivity every 30 seconds, taking
nodes out of the backend pool when health probes fail. An idle timeout of 5 minutes
is also configured.

[[application-gateway]]
==== Application Gateway
An OSI layer 7 load balancer configured with a dynamically assigned public IP address
that can be used to send requests to Elasticsearch from the public internet. {applicationgateway}[Application
Gateway] can be configured with a certificate to configure SSL/TLS between the client
and Application Gateway, performing SSL termination at the gateway. The following parameters are used
to configure Application Gateway

`vNetAppGatewaySubnetName`::
The subnet name for Application Gateway. Application Gateway can only be deployed into
a subnet that contains Application Gateways. When deploying to an existing virtual
network, the subnet must exist beforehand. Defaults to `es-gateway-subnet`.

`vNetNewAppGatewaySubnetAddressPrefix`::
The address space of the Application Gateway subnet. This must be specified when
deploying a new virtual network. The address space must be large enough for the
specified Application Gateway configuration; see {applicationgatewayfaqs}[Application Gateway FAQs]
for more details

`appGatewayTier`::
The tier of Application Gateway. Either `Standard` or `WAF`. The latter is Web
application firewall (WAF), a feature that provides centralized protection from
common exploits and vulnerabilities based on {owasp30}[OWASP core rule sets 3.0].
Defaults to `Standard`.

`appGatewaySku`::
The size of the Application Gateway. Choose `Small`, `Medium` or `Large`.
When choosing `appGatewayTier` of `WAF`, the size must be at least `Medium`. The
main difference between sizes is the amount of throughput that the Gateway can handle.
Defaults to `Medium`.

`appGatewayCount`::
The number of instances of Application Gateway, from 1 to 10. a minimum value
of 2 is recommended for production loads. Defaults to 2.

`appGatewayCertBlob`::
A Base-64 encoded PKCS#12 archive (.p12/.pfx) containing the certificate
and key for Application Gateway. This certificate is used to configure SSL/TLS to
and from Application Gateway. This is required to correctly configure Application
Gateway.

`appGatewayCertPassword`::
The passphrase for the PKCS#12 archive containing the certificate and key for
Application Gateway. Defaults to empty string.

`appGatewayEsHttpCertBlob`::
The Base-64 encoded public certificate (.cer) used to secure the HTTP layer of
Elasticsearch. This is used by Application Gateway to whitelist certificates used
by the backend pool when configuring end-to-end encryption,
and is required when SSL/TLS is configured for the HTTP layer
of Elasticsearch. See the <<tls, Transport Layer Security>> section for more details.

`appGatewayWafStatus`::
When choosing `appGatewayTier` of `WAF`, this parameter controls the firewall
status, either `Enabled` or `Disabled`. Defaults to `Enabled`.

`appGatewayWafMode`::
When choosing `appGatewayTier` of `WAF`, the firewall mode, either `Detection` or
`Prevention`. Defaults to `Detection`.

When choosing to deploy with Application Gateway, both Application Gateway and
an internal load balancer are deployed; the internal load balancer is configured as
the backend pool for Application Gateway.

A custom health probe is configured that reports healthy for the backend pool for
status codes between 200-399, and for status code 401, which may be returned when
Elastic Stack Security is enabled, since the health probe makes requests without any form
of authentication.

The public IP address of Application Gateway is not returned in the template
outputs, but can be retrieved after successful deployment with

[source,sh]
.Azure CLI 2.0
----
gateway_ip_resource=$(az network public-ip show --name "es-app-gateway-ip" \
  --resource-group "<resource group>")

# jq needs to be installed
gateway_fqdn=$(jq -r .dnsSettings.fqdn <<< $gateway_ip_resource)
gateway_ip="https://${gateway_fqdn}:9200"
----

[source,powershell]
.Azure PowerShell
----
$gatewayIpResource = Get-AzureRmPublicIpAddress -Name "es-app-gateway-ip" `
  -ResourceGroupName "<resource group>"

$gatewayIp = "https://$($gatewayIpResource.DnsSettings.Fqdn):9200"
----

[[azure-arm-template-kibana]]
=== Kibana

Kibana can be deployed in addition to Elasticsearch, providing a visual window and UI into the 
data within Elasticsearch. The version of Kibana deployed is always the same as the version of 
Elasticsearch, ensuring compatibility between the products.

The following parameters can be used to deploy Kibana, and control additional configuration

`kibana`::
Whether to deploy Kibana in addition to Elasticsearch. A value of `Yes` will also deploy Kibana, whilst `No` will not. Defaults to `Yes`.

`vmSizeKibana`::
The {vms}[Azure VM SKU] to use for Kibana. Different VM SKUs have different CPU, RAM,
temporary storage space and network bandwidth. The Kibana VM always uses standard storage for the OS disk. The default value is `Standard_A2_v2`.

[NOTE]
--
The template deploys only a single instance of Kibana. You should ensure that a VM SKU
of sufficient size is chosen to service the expected amount of traffic. A larger VM
SKU will generally be faster to optimize browser bundles and start up than a smaller
VM SKU.
--

`vmKibanaAcceleratedNetworking`::
Whether to enable {acceleratednetworking}[accelerated networking] for Kibana,
which enables single root I/O virtualization (SR-IOV) to a VM, greatly improving its
networking performance. Valid values are `Default`, `Yes`, `No`. The default is `Default`, which
enables accelerated networking for the VM SKUs known to support it.

`kibanaAdditionalYaml`::
Additional configuration that will be applied to the kibana.yml configuration file before start up. 
Each line must be separated by a `\n` newline character, for example
+
[source,text]
----
"server.name: \"My server\"\nkibana.defaultAppId: home" <1>
----
<1> "My server" is enclosed within escaped double quotes because it contains whitespace, and is itself inside of a double quoted string.
+
It is recommended that you run your additional yaml through a {yamllint}[linter] before starting a deployment, as incorrectly formatted yaml will fail the deployment.

Kibana is deployed with

* a public IP address, whose fully qualified domain name and IP address can be retrieved from the <<deployment-outputs, deployment outputs>>
* a network security group that allows TCP traffic from the internet on port 5601, to allow browsers to interact with Kibana. Port 22 also allows TCP traffic from the internet, to allow a user to connect using SSH, and use Kibana as a jumpbox to connect to Elasticsearch node VMs.

Kibana communicates with Elasticsearch through the <<internal-load-balancer, internal load balancer>>

[[azure-arm-template-logstash]]
=== Logstash

Multiple instances of Logstash can be deployed in addition to Elasticsearch, providing a pipeline for ingesting data into Elasticsearch.
The version of Logstash deployed is always the same as the version of Elasticsearch, ensuring compatibility between products.

The following parameters can be used to deploy Logstash, and control additional configuration

`logstash`::
Whether to deploy Logstash in addition to Elasticsearch. A value of `Yes` will also deploy Logstash, whilst `No` will not. Defaults to `No`.

`vmSizeLogstash`::
The {vms}[Azure VM SKU] to use for Logstash. Different VM SKUs have different CPU, RAM,
temporary storage space and network bandwidth. The Logstash VM always uses standard storage for the OS disk. The default value is `Standard_DS1_v2`.

`vmLogstashCount`::
The number of Logstash VMs to deploy. Defaults to `1`.

`vmLogstashAcceleratedNetworking`::
Whether to enable {acceleratednetworking}[accelerated networking] for Logstash,
which enables single root I/O virtualization (SR-IOV) to a VM, greatly improving its
networking performance. Valid values are `Default`, `Yes`, `No`. The default is `Default`, which
enables accelerated networking for the VM SKUs known to support it.

`logstashHeapSize`::
The amount of memory, in megabytes, to allocate to Logstash for the JVM heap.
Default will allocate whatever the default is within jvm.options for the version
of Logstash deployed.

`logstashConf`::
A Base-64 encoded string form of Logstash configuration file with which to start Logstash.
A number of parameters are configured that can be referenced from the configuration file
+
[horizontal]
`${ELASTICSEARCH_URL}`::: the Elasticsearch endpoint
`${LOGSTASH_SYSTEM_PASSWORD}`::: password of the built-in `logstash_system` user
`${ELASTICSEARCH_CACERT}`::: the path to the CA cert used to secure the Elasticsearch HTTP layer.
Only set when Transport Layer Security is configured for the <<http-layer, Elasticsearch HTTP layer>>

[IMPORTANT]
.TLS with Logstash monitoring
--
When Transport Layer Security is configured for the Elasticsearch HTTP layer,
Logstash is configured to perform verification against the certificate presented,
using the CA certificate used to secure the Elasticsearch HTTP layer.

Logstash communicates with Elasticsearch through the IP address of the internal load balancer, which means
that a certificate provided with `esHttpCertBlob` is unlikely to pass hostname
verification. In Logstash 6.4.0+, `xpack.monitoring.elasticsearch.ssl.verification_mode` is set to `none`.
For prior versions of Logstash, monitoring is not enabled when a certificate has been provided with `esHttpCertBlob`.

When a CA certificate is provided with `esHttpCaCertBlob`, the generated certificates used to
secure the Elasticsearch HTTP layer include the internal load balancer IP address, meaning
monitoring can be enabled for all versions where Transport Layer Security is configured
for the Elasticsearch HTTP layer.
--

`logstashKeystorePassword`::
Security password for Logstash keystore, used to store values in Logstash 6.2.0 onwards.
+
If no value is supplied, a password will be generated using the
ARM template `uniqueString()` function.

`logstashAdditionalPlugins`::
Additional Logstash plugins to install.  Each plugin must be separated by a semicolon. For example
+
[source,text]
----
logstash-input-azure_event_hubs;logstash-input-http_poller
----

`logstashAdditionalYaml`::
Additional configuration that will be applied to the logstash.yml configuration file before start up. Each line must be separated by a `\n` newline character, for example
+
[source,text]
----
"pipeline.batch.size: 125\npipeline.batch.delay: 50"
----
+
It is recommended that you run your additional yaml through a {yamllint}[linter] before starting a deployment, as incorrectly formatted yaml will fail the deployment.

Logstash only accessible within the Virtual Network and communicates with Elasticsearch through the <<internal-load-balancer, internal load balancer>>

[[azure-arm-template-security]]
=== Security

Securing Elasticsearch and Kibana is of paramount importance, to prevent
unauthorized access by unknown users and unauthorized access by known users
without the appropriate role required for authorization. In addition, securing
the transport of data and communication between Elasticsearch, Kibana, the browser,
or any other client by encrypting traffic is critical for data integrity.

The ARM template exposes a number of features for securing a deployment in Azure.

[[authentication-and-authorization]]
==== Authentication and Authorization

The default template deployment applies a trial license to the cluster to enable
Elastic Stack features, including Security, for a trial period of 30 days.

As part of the trial, Security features including Basic Authentication are enabled,
by {xpackenabled}[configuring `xpack.security.enabled: true`
in Elasticsearch configuration]. This prevents anonymous access to the
cluster.

include::trial-license-warning.asciidoc[]

include::basic-security.asciidoc[]

The following parameters are used to configure initial user accounts

`securityBootstrapPassword`::
Security password for {bootstrappassword}[`bootstrap.password` key] added to the Elasticsearch keystore.
The bootstrap password is used to seed the built-in users.
+
If no value is supplied, a 13 character password will be generated using the
ARM template `uniqueString()` function.

`securityAdminPassword`::
Security password for the `elastic` superuser built-in user account. Must be greater
than six characters in length.
+
[IMPORTANT]
--
Keep this password somewhere safe; You never know when you may need it!
--

`securityKibanaPassword`::
Security password for the `kibana` built-in user account. This is the account that
Kibana uses to communicate with Elasticsearch. Must be greater
than six characters in length.

`securityLogstashPassword`::
Security password for the `logstash_system` built-in user account. This is the account that
Logstash can use to communicate with Elasticsearch. Must be greater
than six characters in length.

`securityBeatsPassword`::
Security password for the `beats_system` built-in user account. This is the account that
Beats can use to communicate with Elasticsearch. Must be greater
than six characters in length. Valid only for Elasticsearch 6.3.0+

`securityApmPassword`::
Security password for the `apm_system` built-in user account. This is the account that the 
APM server can use to communicate with Elasticsearch. Must be greater
than six characters in length. Valid only for Elasticsearch 6.5.0+

`securityRemoteMonitoringPassword`::
Security password for the `remote_monitoring_user` built-in user account. This is the account that 
Metricbeat uses when collecting and storing monitoring information in Elasticsearch. 
It has the `remote_monitoring_agent` and `remote_monitoring_collector` built-in roles.
Valid only for Elasticsearch 6.5.0+

It is recommended after deployment to use the `elastic` superuser account to create
additional individual user accounts that will be needed for users and applications
to interact with Elasticsearch and Kibana, and use these accounts going
forward.

[[saml-single-sign-on]]
==== SAML single sign-on with Azure Active Directory

Using SAML single sign-on (SSO) for Elasticsearch with Azure Active Directory (AAD)
means that Elasticsearch does not need to be seeded with any user accounts from the directory.
Instead, Elasticsearch is able to rely on the claims sent within a SAML token in
response to successful authentication to determine identity and privileges.

To integrate SAML SSO, the following conditions must be satisfied:

* `esVersion` **must** be one that supports the SAML realm i.e. Elasticsearch 6.2.0 or later
* `xpackPlugins` **must** be `Yes` to install a trial license of Elastic Stack platinum features
* `kibana` **must** be `Yes` to deploy an instance of Kibana
* `esHttpCertBlob` _or_ `esHttpCaCertBlob` **must** be provided to configure SSL/TLS for the HTTP layer of Elasticsearch.

SAML integration with AAD defines a SAML realm with the name `saml_aad` in the
elasticsearch.yml configuration file. The Basic Authentication realm is also
enabled, to provide access to the cluster through the built-in users configured
as part of the template. The built-in users can be used to perform additional steps
needed within Elasticsearch to complete the integration.

The following sections guide you through what is required to integrate SAML SSO
with AAD for Elasticsearch and Kibana deployed through the ARM template.

[[create-enterprise-application]]
===== Create Enterprise application

To integrate Elasticsearch with AAD for SAML SSO, it's necessary to create an Enterprise Application within AAD _before_ deploying Elasticsearch with the ARM template. An Enterprise application can be created in the Azure Portal by first navigating to Azure Active Directory

image:images/azure_active_directory.png[]

Choosing Enterprise applications from the AAD blade

image:images/enterprise_application.png[]

And then creating a new application using the `+ New application` button. This will bring up a new blade where a new Enterprise application can be added

image:images/configure_non_gallery_application.png[]

Configure a non-gallery application and give it a name, such as Elasticsearch.

[[configure-enterprise-application]]
===== Configure enterprise application

To configure the enterprise application for SAML SSO, navigate to it in the
AAD blade under `Enterprise Applications`, and select the `Single sign-on` navigation item

image:images/enterprise_application_saml_configuration.png[]

Make a note of the App Federation Metadata Url, as you will need this when
deploying Elasticsearch on Azure.

If you will be configuring a `CNAME` DNS record entry for Kibana, configure the
Identifier (EntityID) input with the domain that you'll be using. For example,
if setting up a `CNAME` of `saml-aad` on the `elastic.co` domain to point to Kibana, the value would be `\https://saml-aad.elastic.co:5601` for Identifier (EntityID).
Additionally, the Reply URL input would be `\https://saml-aad.elastic.co:5601/api/security/v1/saml`. If you will not be configuring
a `CNAME`, simply leave these blank for now.

[[saml-token-attributes]]
===== SAML token attributes

The User Attributes section lists the attributes that will be returned in a SAML token
upon successful authentication

image:images/saml_token_attributes.png[]

You can add here any additional attributes that you wish to be included as
claims in the SAML token returned after successful authentication.

[[application-manifest]]
===== Application manifest

When an Enterprise application is first created, an {applicationmanifest}[Application Manifest]
is also created that controls the application's identity configuration with
respect to AAD. Amongst other things, the app manifest specifies which roles can
be declared for the Enterprise application, in the `appRoles` array.

To view the `appRoles`, navigate to the `App registrations` menu item within the
Azure Active Directory blade, select the Enterprise application in question, and click the Manifest button

image:images/application_manifest.png[]

The manifest is a JSON object that will look similar to

[source,json]
----
{
  "appId": "<guid>",
  "appRoles": [
    {
      "allowedMemberTypes": [
        "User"
      ],
      "displayName": "User",
      "id": "<guid>",
      "isEnabled": true,
      "description": "User",
      "value": null
    },
    {
      "allowedMemberTypes": [
        "User"
      ],
      "displayName": "msiam_access",
      "id": "<guid>",
      "isEnabled": true,
      "description": "msiam_access",
      "value": null
    }
  ],
  ... etc.
}
----

Add role objects to the `appRoles` array for the roles that you wish to be able to assign
users within AAD to. A recommendation here is to add the built-in roles available within
Elasticsearch, for example, the `superuser` role, etc. Each role needs a unique identifer and can be given a description

[source,json]
----
{
  "appId": "<guid>",
  "appRoles": [
    {
      "allowedMemberTypes": [
        "User"
      ],
      "displayName": "Superuser",
      "id": "18d14569-c3bd-439b-9a66-3a2aee01d14d",
      "isEnabled": true,
      "description": "Superuser with administrator access",
      "value": "superuser"
    },
    ... other roles
  ],
  ... etc.
----

After adding the necessary roles, save the manifest.

[[assign-users-to-enterprise-application]]
===== Assign users and groups to Enterprise application

Now that the Enterprise application roles are configured, users and groups within
AAD can be granted access to the Enterprise application and be assigned one of
the application roles

image:images/add_user_to_role.png[]

[[configuring-elasticsearch-for-saml-single-sign-on]]
==== Configuring Elasticsearch for SAML SSO

With Azure Active Directory configured, the following parameters can be used to
configure Elasticsearch for SAML SSO

`samlMetadataUri`::
the URI from which the metadata for the Identity Provider can be retrieved. Use the App Federation Metadata Url of the Enterprise application created in Azure.

`samlServiceProviderUri`::
An optional URI of the Service Provider. This will be the valuesupplied for the Identifier (EntityID) field, when using a `CNAME` DNS record entry to point to the instance of Kibana deployed.
+
If not specified, the value used will be the fully qualified domain name of the public IP address assigned to the deployed Kibana instance.

For a production environment, it's strongly recommended to also configure SSL/TLS for communication with Kibana using `kibanaCertBlob` and `kibanaKeyBlob` parameters. Consult the <<tls, Transport Layer Security>> section for further details on configuring SSL/TLS for Elasticsearch and Kibana.

An example of a minimum deployment is

[source,sh]
[subs="attributes"]
.Azure CLI 2.0
----
template_version={version}
template_base_uri="https://raw.githubusercontent.com/elastic/azure-marketplace/$template_version/src/"

# certificates for SSL/TLS
http_cert=$(base64 /mnt/c/http.p12)
kibana_cert=$(base64 /mnt/c/kibana.crt)
kibana_key=$(base64 /mnt/c/kibana.key)

resource_group="<resource group>"
location="<location>"

# App Federation Metadata Url of the Enterprise application
metadata_uri="https://login.microsoftonline.com/<guid>/federationmetadata/2007-06/federationmetadata.xml?appid=<guid>"

az group create --name $resource_group --location $location

az group deployment create \
    --resource-group $resource_group \
    --template-uri $template_base_uri/mainTemplate.json \
    --parameters _artifactsLocation=$template_base_uri \
        esClusterName=elasticsearch \
        esHttpCertBlob=$http_cert \
        adminUsername=russ \
        authenticationType=password \
        adminPassword=Password1234 \
        securityBootstrapPassword=BootstrapPassword123 \
        securityAdminPassword=AdminPassword123 \
        securityKibanaPassword=KibanaPassword123 \
        securityLogstashPassword=LogstashPassword123 \
        securityBeatsPassword=BeatsPassword123 \
        securityApmPassword=ApmPassword123 \
        securityRemoteMonitoringPassword=RemoteMonitoringPassword123 \
        kibanaCertBlob=$kibana_cert \
        kibanaKeyBlob=$kibana_key \
        samlMetadataUri=$metadata_uri
----

[source,powershell]
[subs="attributes"]
.Azure PowerShell
----
$templateVersion = "{version}"
$templateBaseUri = "https://raw.githubusercontent.com/elastic/azure-marketplace/$templateVersion/src/"

# certificates for SSL/TLS
$httpCert = [Convert]::ToBase64String([IO.File]::ReadAllBytes("C:\http-cert.pfx"))
$kibanaCert = [Convert]::ToBase64String([IO.File]::ReadAllBytes("C:\kibana.crt"))
$kibanaKey = [Convert]::ToBase64String([IO.File]::ReadAllBytes("C:\kibana.key"))

$resourceGroup = "<resource group>"
$location = "<location>"

# App Federation Metadata Url of the Enterprise application
$metadataUri="https://login.microsoftonline.com/<guid>/federationmetadata/2007-06/federationmetadata.xml?appid=<guid>"

$parameters = @{
    "_artifactsLocation"= $templateBaseUri
    "esClusterName" = "elasticsearch"
    "esHttpCertBlob" = $httpCert
    "adminUsername" = "russ"
    "authenticationType" = "password"
    "adminPassword" = "Password1234"
    "securityBootstrapPassword" = "BootstrapPassword123"
    "securityAdminPassword" = "AdminPassword123"
    "securityKibanaPassword" = "KibanaPassword123"
    "securityLogstashPassword" = "LogstashPassword123"
    "securityBeatsPassword" = "BeatsPassword123"
    "securityApmPassword" = "ApmPassword123"
    "securityRemoteMonitoringPassword" = "RemoteMonitoringPassword123"
    "kibanaCertBlob" = $kibanaCert
    "kibanaKeyBlob" = $kibanaKey
    "samlMetadataUri" = $metadataUri
}

New-AzureRmResourceGroup -Name $resourceGroup -Location $location

New-AzureRmResourceGroupDeployment -ResourceGroupName $resourceGroup `
  -TemplateUri "$templateBaseUri/mainTemplate.json" `
  -TemplateParameterObject $parameters
----

After cluster deployment, if you didn't provide a value for the `samlServiceProviderUri`,
copy the <<deployment-outputs, `kibana` output>> and paste this value into <<configure-enterprise-application, the
Identifier (EntityID) field for the Enterprise application within AAD>>. Also paste this value into the Reply URL field, followed by `/api/security/v1/saml`.

[[role-mappings]]
==== Role mappings

With the cluster deployed, the {elasticdocs}/security-api-put-role-mapping.html[Role Mapping APIs] are used to configure rules to define how roles received in the SAML token map to roles within Elasticsearch. A SAML realm called `saml_aad` is configured when `samlMetadataUri` parameter is provided, and maps the SAML role claim to the `groups` attribute.

Since SAML SSO integration also configures Basic Authentication access, role mappings
can be added using the `elastic` superuser account. The role mappings that you define will vary depending on the roles that you defined in the `appRoles` array in the  <<application-manifest, Enterprise Application Manifest>>, but as two examples to demonstrate

[source,sh]
----
PUT /_security/role_mapping/saml-kibana-user
{
  "roles": [ "kibana_user" ],
  "enabled": true,
  "rules": {
    "field": { "realm.name": "saml_aad" } <1>
  }
}
----
// CONSOLE
<1> The SAML realm configured by the ARM template

will give the `kibana_user` role to any user authenticated through the `saml_aad` SAML
realm, and

[source,sh]
----
PUT /_security/role_mapping/saml-superuser
{
  "roles": [ "superuser" ],
  "enabled": true,
  "rules": {
    "all": [
      { "field": { "realm.name": "saml_aad" } }, <1>
      { "field": { "groups": "superuser" } } <2>
    ]
  }
}
----
// CONSOLE
<1> The SAML realm configured by the ARM template
<2> The `superuser` role defined in the Enterprise application manifest, and received in the role claim of the SAML token for the authenticated user

[[tls]]
[float]
=== Transport Layer Security

It is strongly recommended that you secure communication when using the template in production. {elasticstack}/security[Elastic Stack Security] can provide Authentication and Role Based Access control, and Transport Layer Security (TLS) can be configured for both Elasticsearch and Kibana.

[[http-layer]]
==== HTTP layer

You can secure HTTP communication to the cluster with TLS on the HTTP layer of Elasticsearch. You would
typically want to do this when also deploying an external loadbalancer or Application Gateway, but you can also
do this when deploying only Kibana, to secure internal traffic
between Kibana and Elasticsearch through the internal load balancer.

Configuring TLS for the HTTP layer requires `xPackPlugins` be set to `Yes` for 5.x versions, 
6.x versions less than 6.8.0 and 7.x versions less than 7.1.0. With `xPackPlugins` set to `Yes`, a trial
license will be applied to the cluster, which allows TLS to be configured on these versions.

The following parameters can be used

`esHttpCertBlob`::
A base 64 encoded string of the PKCS#12 archive containing the certificate and key with which to secure the HTTP layer. This certificate will be used by all nodes within the cluster.

`esHttpCertPassword`::
Optional passphrase for the PKCS#12 archive encoded in `esHttpCertBlob`. Defaults
to empty string as the archive may not be protected.

Typically, `esHttpCertBlob` parameter would be used with
a certificate associated with a domain configured with
a `CNAME` DNS record pointing to the public domain name
or IP address of the external load balancer or Application
Gateway.

As an alternative to `esHttpCertBlob` and `esHttpCertPassword`, the following parameters can be used

`esHttpCaCertBlob`::
A base 64 encoded string of the PKCS#12 archive containing the Certificate Authority (CA)
certificate and key with which to generate a certificate
for each node within the cluster for securing the HTTP
layer. Each generated certificate contains a Subject Alternative Name DNS entry with
the hostname, an ipAddress entry with the private IP address, and an ipAddress
entry with the private IP address of the internal load balancer. The latter allows
Kibana to communicate with the cluster through the internal load balancer with
full verification.

`esHttpCaCertPassword`::
Optional passphrase for the PKCS#12 archive encoded in `esHttpCaCertBlob`. Defaults
to empty string as the archive may not be protected.

[IMPORTANT]
--

When using Application Gateway for the `loadBalancerType`, you can **only** use `esHttpCertBlob` parameter (and optional `esHttpCertPassword`). SSL/TLS to Application Gateway is secured using `appGatewayCertBlob` parameter as described in <<application-gateway, Application Gateway section>>, with Application Gateway performing
SSL offload/termination.

End-to-end encryption when also configuring TLS on the HTTP layer requires passing the public certificate from the PKCS#12 archive passed in the `esHttpCertBlob` parameter as the value of the `appGatewayEsHttpCertBlob` parameter.
This allows Application Gateway to whitelist the certificate used by VMs in the backend pool.

The certificate can be extracted from the PKCS#12 archive using {openssl}[openssl], for example

[source,sh]
----

openssl pkcs12 -in http_cert.p12 -out http_public_cert.cer -nokeys
----

The certificate to secure the HTTP layer *must* include a Subject Alternative Name with a DNS entry that matches the Subject CN, to work with Application Gateway's whitelisting mechanism.
--

[[transport-layer]]
==== Transport layer

You can secure communication between nodes in the cluster with TLS on the Transport layer of Elasticsearch.
Configuring TLS for the Transport layer requires `xPackPlugins` be set to `Yes` for 5.x versions, 
6.x versions less than 6.8.0 and 7.x versions less than 7.1.0. With `xPackPlugins` set to `Yes`, a trial
license will be applied to the cluster, which allows TLS to be configured on these versions.

The following parameters can be used

`esTransportCaCertBlob`::
A base 64 encoded string of the PKCS#12 archive containing the Certificate Authority (CA)
certificate and private key, used to generate a unique certificate for each node within
the cluster. Each generated certificate contains a Subject Alternative Name DNS entry with
the hostname and an ipAddress entry with the private IP address.

`esTransportCaCertPassword`::
Optional passphrase for the PKCS#12 archive encoded in `esTransportCaCertBlob`. Defaults
to empty string as the archive may not be protected.

`esTransportCertPassword`::
Optional passphrase for each PKCS#12 archive generated by the CA certificate supplied in `esTransportCaCertBlob`.

One way to generate a PKCS#12 archive containing a CA certificate and key is using
{elasticdocs}/certutil.html[Elastic's certutil command utility].

[[tls-kibana]]
==== Kibana

You can secure communication between the browser and Kibana with TLS with the following parameters

`kibanaCertBlob`::
A base 64 encoded string of the PEM certificate used to secure communication between the browser and Kibana.

`kibanaKeyBlob`::
A base 64 encoded string of the private key for the certificate, used to secure communication between the browser and Kibana.

`kibanaKeyPassphrase`::
Optional passphrase for the private key encoded in `kibanaKeyBlob`. Defaults to empty string as the private key may not be protected.

==== Passing certificates and archives

All certificates and PKCS#12 archives *must* be passed as base 64 encoded string values. A base 64 encoded value can be obtained using

. {base64}[base64] on Linux, or {openssl}[openssl] on Linux and MacOS
+
[source,sh]
.Using base64
----
httpCert=$(base64 http-cert.p12)
----
+
[source,sh]
.Using openssl
----
httpCert=$(openssl base64 -in http-cert.p12)
----
+
[NOTE]
--
PEM certificates are already base 64 encoded. Irrespective, you should still base 64 encode PEM certificates; _all certificates and PKCS#12 archives_ are expected to be base 64 encoded, to keep template usage simple i.e. if a parameter contains a certificate or archive, base 64 encode it.
--

. using PowerShell on Windows
+
[source,powershell]
.Using PowerShell
----
$httpCert = [Convert]::ToBase64String([IO.File]::ReadAllBytes("c:\http-cert.p12"))
----

[[azure-arm-template-plugins]]
=== Plugins

An ARM template deployment can include additional plugins, so long as those plugins
can be downloaded from a public URI at deployment time.

[[x-pack]]
[float]
=== Elastic Stack features (formerly X-Pack)

A trial license for the {subscriptions}[platinum features] of the Elastic Stack can be deployed for
Elasticsearch, and Kibana and Logstash if also deployed, using the following parameter

`xPackPlugins`::
Select `Yes` to install a trial license of the Elastic Stack platinum features. A trial license
provides access to {subscriptions}[platinum features] for 30 days. a value of `No`
+
. for Elasticsearch and Kibana 6.3.0+ will deploy with a free perpetual basic license
providing access to the {subscriptions}[basic features]. These versions use a distribution with
Elastic Stack features included in the installation, and the license applied determines which
features are activated.
. for Elasticsearch and Kibana prior to 6.3.0, the X-Pack plugin will not be
installed when a value of `No` is passed. These versions require the X-Pack plugin to
be installed to be able to apply a license and access features related to that license.
+
The default is `Yes`.

include::trial-license-warning.asciidoc[]

[[azure-repository]]
[float]
=== Azure repository

The ARM template can be configured with the
{elasticguide}/plugins/{current}/repository-azure.html[Azure repository plugin] to allow
snapshotting of data within the cluster to an Azure storage account, and restoration
of a snapshot. A separate Azure storage account can be used for this purpose or
alternatively, the shared Azure storage account deployed as part of the template
can be used.

[TIP]
--
It is recommended to use a separate storage account in another resource
group with azure repository plugin so that deleting the resource group in
which a cluster resides does not accidently delete snapshot data as well.
--

The following parameters can configure Azure repository

`azureCloudPlugin`::
Either `Yes` or `No` to install the Azure repository plugin. Default is `No`.

`azureCloudStorageAccountName`::
Optional name of an existing storage account to configure Azure repository plugin.
Must be a valid Azure Storage Account name. If no value is passed and `azureCloudPlugin`
is `Yes`, the shared storage account deployed with the template will be used.

`azureCloudStorageAccountResourceGroup`::
Optional name of the resource group in which the existing storage account named
in `azureCloudStorageAccountName` is located, to configure Azure repository plugin. If the
storage account exists in the resource group targeted by the deployment, this can be left
empty.

The Azure repository plugin does **not** create the container within the
storage account when creating a repository using the {elasticdocs}/modules-snapshots.html[Snapshot API]; the container
**must** be created before creating a repository

[source,sh]
.Azure CLI 2.0
----
# jq needs to be installed
export AZURE_STORAGE_CONNECTION_STRING="$(az storage account show-connection-string \
  --name '<storage account name>' --resource-group '<resource group>' \
      | jq -r .connectionString)"

az storage container create --name "<container name>"
----

[source,powershell]
.Azure PowerShell
----
Set-AzureRmCurrentStorageAccount -ResourceGroupName "<resource group>" `
    -Name "<storage account name>"
New-AzureStorageContainer -Name "<container name>"
----

then the Azure repository can be created using the Snapshot API

[source,js]
----
PUT _snapshot/backup_1
{
  "type": "azure",
  "settings": {
    "container": "<container name>"
  }
}
----
// CONSOLE

[[miscellaneous-plugins]]
[float]
=== Miscellaneous plugins

Other plugins can be installed at deployment time using the following parameter

`esAdditionalPlugins`::
Additional Elasticsearch plugins to install. Each plugin name must be separated by a
semicolon. For example,
+
`analysis-icu;ingest-geoip;ingest-attachment`

Any additional plugins installed are added to the
{elasticguide}/plugins/{current}/_plugins_directory.html[`plugin.mandatory` setting
in elasticsearch.yml configuration], to ensure that a node will start only when
it has all mandatory plugins.
